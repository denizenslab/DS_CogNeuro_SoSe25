{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrasting experimental conditions\n",
    "In this week's lecture we covered one method for contrasting brain activity in response to different kinds of trials. For this lab, we'll look at the ERP in response to another kind of event: auditory and visual. Each of these should have their own signature pattern of activity, as well as distributions across the brain. We'll then transition over to ECoG, where we can investigate how the patterns of specificity differ.\n",
    "\n",
    "Finally, we'll also use resampling (bootstrap) statistics in order to both illustrate the variability present in our signals, as well as to make inferential statements about \"how much\" the brain activity differs between conditions.\n",
    "\n",
    "# The Data\n",
    "We'll use the same data from lecture in order to look at the activity in EEG. Our ECoG data will be the consonant / dissonant chords task we covered last week. This time, we'll start to incorporate more information about the trials into our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import datascience as ds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neurods as nds\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_data_root = '../../data/eeg/mne_sample/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, load \n",
    " + the data ('mne_sample-raw.fif')\n",
    " + the events ('mne_sample-events.csv')\n",
    " + the event information ('mne_sample-event_info.csv') \n",
    "using the path_data_root path.\n",
    "\n",
    "To load the data use MNE and make sure to preload the data.\n",
    "To load the events file use datascience tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, take a look again at what's inside the `ev_info` object. This tells us what kinds of trials we've got.\n",
    "* Use it to create a dictionary that maps event names (strings) onto event ids (integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, look at the `ev_df` object. This contains our actual event times, as well as which event type is associated with that time.\n",
    "* Turn this events object into an MNE events array. Use the 'select' function. Remember, this is an array of shape `(n_events, 3)`. First column is the event index, second column is previous value, which is, `0`s, third column is the event type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, create the `Epochs` object associated with these events.\n",
    "* Then, keep only the \"Left Audio (LA)\" and \"Left Visual (LV)\" event types. You can pass a list of event type strings to the `Epochs` object to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the average of each trial type using the MNE `Evoked` object.\n",
    "* Mark the electrode name that has the highest deflection in each case. You should be able to click each line to display the channel name (make sure `%matplotlib notebook` has been run before this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, make a `joint` plot for each condition that shows the topographies across the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* Does there seem to be a clear pattern on the head for each one? What about a difference in how the activity progresses in time?\n",
    "\n",
    "# Global Field Power\n",
    "Assess the general pattern of activity across *all* electrodes. We'll calculate this below.\n",
    "\n",
    "* First, calculate the mean across all trials for each stimulus type. Remember to square the result.\n",
    "* Calculate the mean and standard error across all channels for each stimulus type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the mean +/- standard error for each trial type. Make them two different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Can you make any sense of these two patterns of activity?\n",
    "* Do the plots tend to be larger or smaller in certain times over others?\n",
    "* What can you say about the auditory vs. visual system from this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERPs in ECoG\n",
    "Next we'll focus on the same trial averaging approaches that we've learned about in EEG. We'll see if the same kinds of signals come out of this approach, and examine the brain activity under a slightly more complex experiment.\n",
    "\n",
    "This dataset was recorded during a task in which subjects listened to musical chords. These chords were either consonant, or dissonant. It was used to investigate whether auditory regions of the brain change their activity in response to these different types of sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data_root = '../../data/ecog/chords_task/'\n",
    "\n",
    "\n",
    "# Then load in the channel layout file as well as an image of the brain \n",
    "# You will use these two variables at the end of the lab for plotting in ECoG\n",
    "lt = mne.channels.read_layout(path_data_root + 'brain.lout')\n",
    "im = plt.imread(path_data_root + 'brain.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, load \n",
    " + the data ('ecog_resamp-raw.fif')\n",
    " + and event information ('meta_time.csv')\n",
    "\n",
    "To load the data use MNE and make sure to preload the data.\n",
    "To load the events file use datascience tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the raw data. Remember to put the right \"scanling\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Look at our events object and see what kind of data we have\n",
    "* Show the unique values in the `type` column to see what kinds of events exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many event types do we have? Create a dictionary that maps the event names to event IDs for these events. For example, if the event types are \"A\", \"B\", \"C\", we want you to map it to 1, 2, 3 (or some other unique ID of your choice))\n",
    "* Then, create a list of event IDs that maps onto the event onsets in this table. One ID for each event. \n",
    "(HINT: Use np.where function). Make sure you have the same amount of event IDs as you have envents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now convert the events object into an events array that can be later used in MNE. Remember that the first column should be the 'index' of when that event occurred, the second column is the 'previous value', with zeros; the third column is the 'event_type'. You will need to use the sampling frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using the `Raw` object, along with this events array, create an `Epochs` object. Include times from -200ms to 500ms.\n",
    "* Plot the average responses for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can't make a \"joint\" plot for this, because each ECoG grid has a unique structure and location on the brain, so the \"standard\" scalp topographies won't work.\n",
    "\n",
    "**However**, we can still plot averages using a custom topographic layout. This will give us a rough idea of where on the brain the activity exists.\n",
    "\n",
    "* Use the `plot_topo` method of our `Evoked` object to plot the average waveform at each channel for each stimulus type/condition.\n",
    "  * For a custom layout, use the `layout` parameter along with the layout file we loaded in the beginning of the ECoG section\n",
    "  * To plot the image of the brain as well, use the `fig_background` parameter and pass the image file that we loaded in the beginning of the ECoG section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping waveform confidence intervals\n",
    "Previously we calculated the Global Field Power by combining the activity across many channels. We did this calculating the mean and standard error, which is a parametric way of assessing the variability of a signal.\n",
    "\n",
    "Here, we'll do the same thing with the bootstrap, a resampling method that makes less assumptions about your data. It is a very flexible tool which is used extensively in neuroscience.\n",
    "\n",
    "* Calculate the Global Field Power for each condition of our ECoG data.\n",
    "* Then, use a bootstrap method to put confidence intervals on each timepoint across all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "# Take the average across all trials for these electrodes\n",
    "\n",
    "\n",
    "# you can use nds.stats.bootstrap_func() for boostrapping across the average of all trials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, plot the activity lower and upper bound (across time) from our bootstrap results for each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "# Now plot the comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What can you conclude from this? \n",
    "* Is there a \"difference\" between these two types of chords?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping a statistical test (Optional)\n",
    "The final part of this lab will try to determine whether there is a \"real\" difference between these two conditions. For a window from 200ms to 250ms post-stimulus, we'll test for the difference in average amplitude between these two groups. \n",
    "\n",
    "* Plot a histogram of the average amplitude within the time window (the data should be shape (n_channels,) for each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "# you can make use of nds.utils.time_mask() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, using a bootstrap method: \n",
    "* Construct a 95% confidence interval for the *difference in average amplitude (across channels)* between condititions within this time window. \n",
    "* Do the same for a 99% confidence interval.\n",
    "* Plot a histogram showing the bootstrap results, and vertical lines for the confidence interval. Use the color *red* for the 95% confidence interval, and *black* for the 99% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STUDENT ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STUDENT ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How would you describe what these bootstrap intervals mean?\n",
    "* Looking at these confidence intervals, do you think there is a difference between the groups?\n",
    "* Does each interval give you the same interpretation? Why or why not?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

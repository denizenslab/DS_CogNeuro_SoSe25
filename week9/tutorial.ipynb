{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event-related averages of fMRI data and fMRI impulse response function\n",
    "\n",
    "\n",
    "We will introduce the way we formalize the organization of an experiment in a *design matrix*.\n",
    "\n",
    "# Goals\n",
    "\n",
    "* Experimental Design (continued): Block Design vs. Event-Related Design\n",
    "* Block Design Analysis (Average Response)\n",
    "    * Compute averages of activity for different types of events in a localizer experiment.\n",
    "* Understand how responses to stimuli evolve over time\n",
    "* Accounting for the fMRI hemodynamic response function (HRF)\n",
    "\n",
    "\n",
    "<a id=\"Experimental_Design\"></a>\n",
    "# Experimental design\n",
    "\n",
    "Cognitive neuroscientists conduct fMRI experiments to learn something about how cognition is related to brain responses, and where in the brain those responses occur. Cognition is a term that describes mental processes such as attention, memory, perception, decision making, planning, language, motor control or emotion. Since we can't measure mental phenomena directly, we either characterize properties of stimuli used or record behavior as a proxy for the cognitive processes that we believe underlie those behaviors. Before we learn the techniques that allow neuroscientists to relate those stimuli and behaviors to brain responses, we'll first spend some time discussing how fMRI experiments are designed, and the reasons behind some of those design decisions. \n",
    "\n",
    "Broadly speaking, we must be concerned with 2 aspects of an experiment:\n",
    "\n",
    "\n",
    "1. **Cognitive Process Elicitation:** The experiment must be designed to elicit the cognitive process or processes that we're trying to understand. This is generally done by presenting the participant with a stimulus, asking them to complete some task, or a combination of both. For example:\n",
    "    * A stimulus-only experiment could involve simply showing the participant some movies while they lie in the MRI scanner and look wherever they want at the movie. This would elicit neural activity in the visual system, and the scientist could study which parts of the visual system respond to which types of stimuli.\n",
    "    * A task-only experiment could involve asking the subject to start counting from 0 to 100 saying one number every second. This would elicit neural activity in the speech production region of the brain.\n",
    "    * A stimulus and task experiment could involve showing participants a set of images, showing them a second set of images and asking them to indicate if they had already seen this image. This would elicit neural activity in regions responsible for encoding and retrieving memories.\n",
    "    \n",
    "2. **Technical Considerations:** Any experiment involves taking measurements of the phenomena being studied. Considering all the ways your measurement tools affect the data collection is crucial to collecting data that is high quality. While there are many considerations when using an MRI scanner to collect BOLD data, we will be primarily concerned with accounting for two properties of the BOLD signal: \n",
    "    * The BOLD signal is **slow**\n",
    "    * The BOLD signal is **noisy**\n",
    "  \n",
    "## Block vs. event-related designs\n",
    "\n",
    "While the first concern just mentioned (eliciting cognitive processes to study) differs from experiment to experiment, the technical considerations of doing fMRI studies are common to all. Let's explore 2 broad classes of experimental designs that deal with the two technical considerations mentioned above:\n",
    "<a id=\"Block_Design\"></a>\n",
    "\n",
    "1\\. **Block Design:** Block designs consist of presenting many stimuli (or trials types) of the same type together in a row, or a block. The BOLD response to this block of stimuli can then be averaged to investigate which brain regions respond more to a particular stimuli than others. This averaging of TRs in a block design helps to improve the SNR. This improvement in SNR from using a block design comes at a cost, however: block designs are not temporally efficient, they take a long time to show just a few different types of stimuli. Since time in the MRI machine is expensive (several hundred dollars an hour), this is not an efficient way to conduct fMRI research. Here's a schematic of an example block design alternating blocks of doing a task (T) or rest (C), along with a BOLD signal that just responds to the task.\n",
    "\n",
    "![alt text](../../data/images/block_bold.png \"block_bold.png\")\n",
    "\n",
    "<a id=\"Event_Related_Design\"></a>\n",
    "2\\. **Event-Related Design:** In a fast event-related design experiment, many different stimuli are presented at much shorter intervals. While this design is more temporally efficient (which allows for more complex experiments), a potential problem with event-related designs is that the BOLD signal responds slowly (peaks at about 5 seconds), and so if we show many different types of stimuli in a row, the BOLD signal response from one stimulus will \"bleed over\" into the TRs of the neighboring stimuli. Thus, if we want to mathematically describe how the brain responds to a given stimulus, we have to incorporate this delay in order to be accurate. See the image below for an illustration of how this might be done.\n",
    "\n",
    "![alt text](../../data/images/event_related.PNG \"event_related.PNG\")\n",
    "\n",
    "This problem of \"bleeding over\" has a solution however, and it involves characterizing the Hemodynamic Response Function (HRF) as we'll see later in this lecture. Since event-related designs are more complex. We'll see later on today how accounting for the HRF can even benefit block design experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import cortex as cx\n",
    "import neurods as nds\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import nibabel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Matplotlib defaults\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Same as previously: load using nibabel, use get_data() method of the nibabel data object, transpose resulting data array, and zscore the data. For now, we will treat this as a generic data set (next week, we will learn more about the experiment that generated this data as we begin to actually analyze the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sub, xfm = 's01', 'catloc'\n",
    "basedir = '../../data/fMRI/categories/'\n",
    "fname = os.path.join(basedir, 's01_categories_01.nii.gz')\n",
    "mask = cx.db.get_mask(sub, xfm, type='cortical')\n",
    "\n",
    "nii = nibabel.load(fname)\n",
    "data = nii.get_fdata().T.astype(np.float64)\n",
    "data = data[:, mask]\n",
    "data = zscore(data, axis=0)\n",
    "\n",
    "print(\"Data dimensions are: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Unmask\n",
    "data3d = nds.fmri.unmask(data[0], mask, bg_value=np.nan)\n",
    "data4d = nds.fmri.unmask(data, mask, bg_value=0)\n",
    "print(\"data3d dimensions are: \", data3d.shape)\n",
    "print(\"data4d dimensions are: \", data4d.shape)\n",
    "\n",
    "# let's plot it\n",
    "def slice_3d_array(vol, axis=0, **kwargs):\n",
    "    \n",
    "    \"\"\"Function to plot slices of a 3D array along a given axis.\"\"\"\n",
    "    \n",
    "    nslices = vol.shape[axis]\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    subplot_size = int(np.ceil(np.sqrt(nslices)))\n",
    "    print(\"{} slices will be visualized\".format(nslices))\n",
    "\n",
    "    for s in range(nslices):\n",
    "        ax = fig.add_subplot(subplot_size, subplot_size, s+1)\n",
    "        if axis==0:\n",
    "            slices = vol[s,:,:]\n",
    "        elif axis==1:\n",
    "            slices = vol[:,s,:]\n",
    "        elif axis==2:\n",
    "            slices = vol[:,:,s]\n",
    "\n",
    "        plt.imshow(slices, **kwargs)\n",
    "        ax.axis('off')\n",
    "        \n",
    "slice_3d_array(data3d, axis=0, cmap=plt.cm.RdBu_r, vmin=-3, vmax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> Two weeks ago, we made a plot of a single slice over time. Can you make a plot like that using slice_3d_array? (Plot the 8th slice over time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick pycortex review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a volume\n",
    "vkw = dict(mask=mask, cmap='RdBu_r', vmin=-3, vmax=3)\n",
    "vol = cx.Volume(data[0], sub, xfm, **vkw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show a flamtap\n",
    "# (If you get an XMLSyntaxError, ignore them; they are not important for now.)\n",
    "try:\n",
    "    _ = cx.quickflat.make_figure(vol)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load description of experiment \n",
    "The experiment we have been working with is a *localizer* experiment. It is designed to find areas of the brain that respond to particular visual categories of objects: faces, bodies, and places. It also reveals areas that respond more to objects than to scrambled versions of the same objects. This experiment is a simple replication of past work, and is commonly done as a first step to locate (or localize) a region of interest for further analysis in a subsequent experiment.\n",
    "\n",
    "For the localizer experiment, images from each category were presented in a block design. This means that images from the one category were shown one after another for a \"block\" of 20 seconds (10 TRs), followed by images from another category for a block of 20 seconds, and so on.\n",
    "\n",
    "![alt text](../../data/images/CategoryLocalizerDesign.001.png \"CategoryLocalizerDesign.001.png\")\n",
    "\n",
    "\n",
    "To analyze the data from this experiment at all, we need to know when the blocks for each category (faces, bodies, places, objects, and scrambled objects) began and ended. This information is stored in a *design matrix*, which we load below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "design = np.load(os.path.join(basedir, 'experiment_design.npz'))\n",
    "print('Experiment design variables: ', sorted(design.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "conditions = design['conditions'].tolist()\n",
    "print('Conditions: ', conditions)\n",
    "design_run1 = design['run1']\n",
    "print('Design shape: ', design_run1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to show a design matrix as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.imshow(design_run1.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> What are the dimensions here? Label the axes on the figure above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find condition onsets\n",
    "Last week for homework you wrote a function to compute event-related averages of data, given condition onset times. Here's a good version of such a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nds.fmri.compute_event_avg??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we don't have explicit times, only logical indices for which timepoints belong to which conditions - so we need to compute when the condition onsets were to use our function, or we need to write a new function! Let's stick with the old one, as we'll use it later, and just find the condition onsets.\n",
    "\n",
    "> Find the onsets for each condition! And make your code into a re-usable function to find onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Find condition onsets\n",
    "cond = 0\n",
    "onsets, = np.nonzero(design_run1[:, cond])\n",
    "onsets = [o for o in onsets if o-1 not in onsets]\n",
    "print(onsets)\n",
    "plt.figure()\n",
    "# Sanity check: did we do that right? \n",
    "plt.plot(design_run1[:,0])\n",
    "# or\n",
    "#plt.stem(design_run1[:,0])\n",
    "plt.plot(onsets, [1, 1], 'ro')\n",
    "plt.ylim([-.5, 1.5])\n",
    "plt.show()\n",
    "\n",
    "# Code\n",
    "def get_onsets(design, cond):\n",
    "    \"\"\"Convert condition design matrix of 1s and 0s to condition onsets \n",
    "    for a specific condition\"\"\"\n",
    "    # Note fancy syntax to avoid tuple output\n",
    "    onsets, = np.nonzero(design[:, cond])\n",
    "    # Doesn't have to be an array, but why not\n",
    "    onsets = np.array([o for o in onsets if o-1 not in onsets])\n",
    "    return onsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "SO: Compute event averages for one condition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cond = 'faces'\n",
    "idx = conditions.index(cond)\n",
    "cond_onsets = get_onsets(design_run1, idx)\n",
    "n_time_points = 10\n",
    "cond_avg = nds.fmri.compute_event_avg(data, cond_onsets, n_time_points)\n",
    "print(\"Condition average (cond_avg) shape:\", cond_avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Show a bunch of flatmaps in sequence\n",
    "vkw = dict(mask=mask, cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "for n, ca in enumerate(cond_avg):\n",
    "    try:\n",
    "        plt.figure()\n",
    "        _ = cx.quickflat.make_figure(cx.Volume(ca, sub, xfm, **vkw), height=300)\n",
    "        plt.title('{n} TRs from onset'.format(n=n))\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "How does the event average change over time? Why do you think this is? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> Do this for all conditions; make your code compact, if you can! Keep your results in a dictionary called event_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "event_avg = {}\n",
    "event_avg_vol = {}\n",
    "conditions = ['body', 'face','object','place','scramble']\n",
    "n_time_points = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accounting for the HRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "we computed event-related averages for responses to different categories of objects. We saw that response in fMRI emerge slowly (2-3 TRs or 4-6 seconds) after the onset of a stimulus. Fundamentally, the most common thing that we want to know in fMRI experiments is how some event is related to brain responses. The event related averages show us that some areas of the brain respond more to some stimuli than others, but we would like a more firm statistical basis before we draw any conclusions from our data.\n",
    "\n",
    "Let's account for the delay in the fMRI signal after a stimulus or other event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### fMRI responses do not occur immediately after a stimulus\n",
    "\n",
    "fMRI responses emerge slowly after the onset of a stimulus (or any other event). This means that, if we want to make an accurate mathematical model of how the brain responds, we have to somehow incorporate this delay into our model. \n",
    "\n",
    "To do this, we will borrow a concept from signal processing theory called the impulse response function. An impulse response function describes the way a signal emerges (for any system) after an event. The way the BOLD response emerges after an experimental event is called the *hemodynamic response function* or HRF. \n",
    "\n",
    "A great deal of early fMRI research went into accurately describing how the BOLD signal rises, falls, and resets to baseline after an event. We will rely on the conclusions of this research without going into much detail about it. For an overview of hemodynamic responses in fMRI, check out [this blog post](https://andysbrainbook.readthedocs.io/en/latest/fMRI_Short_Course/Statistics/03_Stats_HRF_Overview.html), and the papers linked in the lecture slides (Handwerker, Bandettini et al 2012; Logothetis & Wandell, 2004). The practical upshot of this work is that BOLD responses have a fairly characteristic shape, which is well described by a mathematical function called a *gamma function*. \n",
    "\n",
    "We have provided you with a function to produce this canonical HRF within the neurods module: \n",
    "\n",
    "    neurods.fmri.hrf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the TR, or repetition time, a.k.a. the sampling rate for our data\n",
    "\n",
    "TR = 1.0 # One measurement per second\n",
    "\n",
    "# let's import a function that makes hrfs:\n",
    "from neurods.fmri import hrf as generate_hrf\n",
    "\n",
    "# Get a canonical hrf_1\n",
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "print('hrf_1 shape is', hrf_1.shape)\n",
    "__ = plt.plot(t_hrf,hrf_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a response to a single discrete stimulus appearing at time 0, like this:\n",
    "t = t_hrf\n",
    "stimulus = np.zeros(t.shape)\n",
    "stimulus[0] = 1\n",
    "\n",
    "# We will be plotting stimulus / response pairs several times, so let's \n",
    "# just make a function for this right away.\n",
    "def stim_resp_plot(t, stimulus, response, yl=(-0.2, 1.2)):\n",
    "    \"\"\"Plot stimulus and response\"\"\"\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # Note stem() function!\n",
    "    plt.stem(t, stimulus, linefmt='k-', markerfmt='.', basefmt='k-', label='Stimulus')\n",
    "    plt.plot(t, response, 'r.-', label='BOLD response')\n",
    "    plt.ylim(yl)\n",
    "    plt.xlim([-1,t.max()+1])\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Response (arbitrary units)')\n",
    "    _ = plt.legend()\n",
    "\n",
    "# Plot\n",
    "stim_resp_plot(t, stimulus, hrf_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the parameters of the generate_hrf() function. See what happens if you change them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STUDENT ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time an event occurs, this slow hemodynamic response emerges. We will slowly explore how this hemodynamic response can affect the signal in a voxel.\n",
    "\n",
    "First, we start with a hypothetical run of 200 TRs, in which no stimuli is presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200 # Total time points (TRs)\n",
    "t = np.arange(n,)\n",
    "# no stimulus\n",
    "stimuli = np.zeros((n))\n",
    "# we assume no response\n",
    "response = np.zeros((n))\n",
    "# here we plot the function\n",
    "stim_resp_plot(t, stimuli, response, yl=(-0.2, 1.2))\n",
    "# and see nothing as predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw above how the time changes when we have a stimulus at time 0. Imagine we have a stimulus at time i=10. What would happen then to the activity? Just assume that this stimulus will create an hrf that will be *added* to the signal from times i to times i + hrf_length (hrf_length is the length of our theoretical hrf, which was 32 above).\n",
    "\n",
    "Attention: make sure you modify response by adding something to it's values, and not just changing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = len(hrf_1)\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "response = np.zeros((n))\n",
    "\n",
    "i = 10\n",
    "stimuli[i] = 1\n",
    "\n",
    "# now add the response to stimulus i to the response, then plot using stim_resp_plot like above\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say that there were 3 stimuli, one at 10, one at 70 and one at 150, plot the resulting activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = len(hrf_1)\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "response = np.zeros((n))\n",
    "\n",
    "stim_times = [10, 70, 150]\n",
    "for i in stim_times:\n",
    "    stimuli[i] = 1\n",
    "\n",
    "# now add the response to those stimuli i, then plot using stim_resp_plot like above\n",
    "### STUDENT ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now say that the stimuli are closer together than the length of the hemodynamic function: let's say they occur at times 10, 21, 25, 70, 71,74, 75, 80 and 150, what happens? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = len(hrf_1)\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "response = np.zeros((n))\n",
    "\n",
    "stim_times = [10,21,25, 70, 75, 80, 150]\n",
    "for i in stim_times:\n",
    "    stimuli[i] = 1\n",
    "\n",
    "# now add the response to stimulus i to the response, then plot using stim_resp_plot like above\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to your script if the stimulus appears at time 180? If it breaks, you need to make a change involving the min function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = 32\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "response = np.zeros((n))\n",
    "\n",
    "stim_times = [190]\n",
    "for i in stim_times:\n",
    "    stimuli[i] = 1\n",
    "\n",
    "# now add the response to stimulus i to the response, then plot using stim_resp_plot like above\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function that will produce the correct response vectors given the stimulus vector and the hrf_1 vector. The function will go over every element in the stimulus vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = len(hrf_1)\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "\n",
    "stim_times = [10,21,25, 70, 75, 80, 150]\n",
    "for i in stim_times:\n",
    "    stimuli[i] = 1\n",
    "\n",
    "# let's define our function here, then use it to generate output and plot the above plots:\n",
    "def gen_responses(stimulus_vec, hrf_canonical):\n",
    "    n = stimulus_vec.shape[0]\n",
    "    hrf_length = len(hrf_canonical)\n",
    "    response = np.zeros((n,))\n",
    "    for i in range(n):\n",
    "        if stimulus_vec[i]==1: # one way to do it: only if I have a stimulus, I will add a response\n",
    "            index = range(i, min(i+hrf_length,n) )\n",
    "            response[index] += hrf_canonical[:len(index)]\n",
    "    return response\n",
    "\n",
    "response = gen_responses(stimuli,hrf_1)\n",
    "stim_resp_plot(t, stimuli, response, yl=(-0.2, 1.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assume that the stimulus occurs with different intensities: for example, a tactile stimulus with different levels of intensities. The assumption is that the response from the occurence of each feature is proportional to the intensity of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = len(hrf_1)\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "\n",
    "stim_times = [10,21,25, 70, 75, 80, 150]\n",
    "stim_intensities = [0.25,0.25,1, 1, 1, 0.5, 0.5]\n",
    "for idx, i_time in enumerate(stim_times):\n",
    "    stimuli[i_time] = stim_intensities[idx]\n",
    "\n",
    "def gen_responses(stimulus_vec, hrf_canonical):\n",
    "    n = stimulus_vec.shape[0]\n",
    "    hrf_length = len(hrf_canonical)\n",
    "    response = np.zeros((n,))\n",
    "    for i in range(n):\n",
    "        index = range(i, min(i+hrf_length,n) )\n",
    "        response[index] +=  stimuli[i]*hrf_canonical[:len(index)]\n",
    "    return response\n",
    "\n",
    "response = gen_responses(stimuli,hrf_1)\n",
    "stim_resp_plot(t, stimuli, response, yl=(-0.2, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say we have a blocked stimulus, i.e. the simulus is on for 30 seconds, starting at 10, 70 and 130:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = 32\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "\n",
    "stim_times = list(range(10,40)) + list(range(70,100))+ list(range(130,160))\n",
    "for i in stim_times:\n",
    "    stimuli[i] = 1\n",
    "\n",
    "# we can use your function here again, then use it to generate output and plot the above plots:\n",
    "def gen_responses(stimulus_vec, hrf_canonical):\n",
    "    n = stimulus_vec.shape[0]\n",
    "    hrf_length = len(hrf_canonical)\n",
    "    response = np.zeros((n,))\n",
    "    for i in range(n):\n",
    "        index = range(i, min(i+hrf_length,n) )\n",
    "        response[index] +=  stimuli[i]*hrf_canonical[:len(index)]\n",
    "    return response\n",
    "\n",
    "response = gen_responses(stimuli,hrf_1)\n",
    "stim_resp_plot(t, stimuli, response, yl=(-0.2, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectively, a train of 30 spikes at the sampling frequency 1s is the same as having a constant step function for 30 seconds. What we did above is called a convolution: we have a signal, the stimulus. This signal is going to be modified by a function, the hrf in our case. Convolution is an integration operation where you integrate an initial signal with a modifying function, in a way that reflects how previous values of the signal (before time i) affect the new transformed signal (at time i). What we did above is a simplified integration: we are working in discrete time and we manually added the contributions at each time. \n",
    "\n",
    "This is what we did:\n",
    "Let's call $T$ the length of the HRF. We went though the stimulus and made it affect the response at later stages. At the end, every value of the response $r(i)$ will have contributions to the stimulus $s$ from the previous $T$ time points:\n",
    "\n",
    "$r(i) = s(i-1) \\times hrf(1) +  s(i-2) \\times hrf(2) + ... +  s(i-T+1)  \\times hrf(T) \\\\\n",
    "  \\ \\ \\   = \\Sigma_{\\tau=1}^{T} s(i-\\tau) \\times h(\\tau)$\n",
    "\n",
    "This is exactly the expression of the discrete convolution function between functions $s$ and $h$. In continuous time, the convolution operation is written as:\n",
    "\n",
    "$r(i) = \\int_{\\tau=1}^{T} s(i-\\tau) \\times h(\\tau) = s \\ast h(i)$\n",
    "\n",
    "Here we will use a numpy function that is already implemented for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = 32\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "#response = np.zeros((n))\n",
    "\n",
    "stim_times = list(range(10,40)) + list(range(70,100))+ list(range(130,160))\n",
    "for i in stim_times:\n",
    "    stimuli[i] = 1\n",
    "\n",
    "response = np.convolve(stimuli, hrf_1, mode='full')\n",
    "print('resulting response has length {} and should be cropped'.format(len(response)))\n",
    "# Here we also have to crop the signal because np.convolve creates a signal longer than n\n",
    "# because it computes the response of stimuli appearing up to time n-1, which affect the \n",
    "# signal for longer than n.\n",
    "stim_resp_plot(t, stimuli, response[:n], yl=(-0.2, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another example: the convolution of a simple periodic signal with the HRF function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = 32\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "#response = np.zeros((n))\n",
    "\n",
    "stim_times = range(0,200,20)\n",
    "for i in stim_times:\n",
    "    stimuli[i] = 1\n",
    "    \n",
    "response = np.convolve(stimuli, hrf_1, mode='full')\n",
    "# Here we also have to crop the signal!\n",
    "stim_resp_plot(t, stimuli, response[:n], yl=(-0.2, 1.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now of overlapping events:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hrf, hrf_1 = generate_hrf(tr=TR)\n",
    "hrf_length = 32\n",
    "n = 200\n",
    "t = np.arange(n,)\n",
    "stimuli = np.zeros((n))\n",
    "#response = np.zeros((n))\n",
    "\n",
    "idx = np.arange(0, n, 20)\n",
    "stimuli[idx] = 1\n",
    "add = np.arange(len(idx), 0, -1)\n",
    "stimuli[idx+add] = 1 \n",
    "    \n",
    "response = np.convolve(stimuli, hrf_1, mode='full')\n",
    "# Here we also have to crop the signal!\n",
    "stim_resp_plot(t, stimuli, response[:n], yl=(-0.2, 1.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Observation \n",
    "So far we have assumed that every stimulus occurence creates a response in the voxel equal to the canonical hrf (and can be scaled by the feature value).\n",
    "\n",
    "However, voxels in different parts of the brain can be differently responsive to a stimulus, or not responsive at all. In fMRI, we are interested in finding how responsive different voxels are to a stimulus. We will therefore introduce a new parameter: $w^v$, that describes the strength with which a voxel $v$ responds to the stimulus:\n",
    "\n",
    "$ r^v(i) = w^v \\times  (s \\ast hrf (i) )$\n",
    "\n",
    "We already know how to compute $s \\ast hrf (i)$. In the previous examples we implicitely used $w^v = 1$, and assumed the voxel responds to the stimulus. We will gradually learn how we can estimate $w^v$ from the data, i.e. try to find how responsive voxel $v$ is to a stimulus, if at all. \n",
    "\n",
    "\n",
    "Next, we will show you two ways to account for this delay when trying to assess the relationship between brain signals and stimulus events. \n",
    "\n",
    "## Let's go back to the data\n",
    "For these exercises, we will work with the data from a subset of voxels for the faces condition. We use the same plotting function, but we plot the data that is provided to us instead of forming the responses ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = design_run1[:, 1] #face condition\n",
    "data_sim = np.mean(data[:, [6,57,37]], axis=1) #averaging over ffa voxels\n",
    "t = np.arange(1, data_sim.shape[0]+1, 1)\n",
    "stim_resp_plot(t, stimulus, data_sim, yl=(-2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(stimulus, data_sim);\n",
    "plt.show()\n",
    "print(\"the correlation between the stimulus and the data is {}\".format(np.corrcoef(stimulus, data_sim)[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the presentation of the stimulus should create a hemodynamic response if this voxel is sensitive to that stimulus. We therefore need to convolve the stimulus first with the hemodynamic response. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2, hrf_2 = nds.fmri.hrf(tr=1)\n",
    "plt.figure()\n",
    "plt.plot(t2, hrf_2);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can convolve the stimulus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_stimulus = np.convolve(stimulus, hrf_2, mode='full')[:120]\n",
    "stim_resp_plot(t, conv_stimulus, data_sim, yl=(-2, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(conv_stimulus, data_sim);\n",
    "plt.show()\n",
    "print(\"the correlation between the stimulus and the data is {}\".format(np.corrcoef(conv_stimulus, data_sim)[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now we are able to recover a clearer relationship between the stimulus and the data. What is the variance of the noise that we can guess from this plot? Usually in fMRI we are not so lucky to have effects that are very clear. We will study in future lectures how to can expand this analysis.\n",
    "\n",
    "Can we estimate from this data the magnitude of the weight $w_v$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function first a straight line through the points above\n",
    "slope, intaercept = np.polyfit(data_sim, conv_stimulus, 1)\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, what is units of this value? FMRI signal doesn't have a unit and can be rescaled and normalized. The weight therefore depends on how the data is normalized and is meaningful only with respect to the variance of the data. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

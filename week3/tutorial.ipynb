{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Now that we've taken a look at raw data, it's time to start doing things with this data. Today we'll focus on finding events of interest in the brain activity. Specifically, we're going to focus on one of the most important tasks in any neuroscience analysis: **cleaning messy data**. There are many, many sources of noise in neuroscience, and the first step in any analysis should be to check it out and determine what's going on. \n",
    "\n",
    "## Goals for today\n",
    "* Examining where channels lie on a person's scalp in EEG\n",
    "* Looking at one of the most common sources of noise in EEG: eyeblinks.\n",
    "* Extracting windows of time before/after each eyeblink\n",
    "* Investigating scalp topographies to see how they relate to muscle activity.\n",
    "* Calculating the \"average\" eyeblink, and removing it from our data.\n",
    "\n",
    "---\n",
    "\n",
    "# Slicing up data\n",
    "Thus far, we've only browsed through raw data. However, recording from the brain is only half of the battle. We also need to understand what happened *in the outside world* in order to figure out why the brain is doing what it did.\n",
    "\n",
    "Today, we'll attempt to understand a little more about how we can relate the outside world to the brain activity that we record.\n",
    "\n",
    "First, we'll load some data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import sys\n",
    "import neurods as nds\n",
    "import datascience as ds\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This time, we'll load both the raw data AND some events\n",
    "data_path = '../../data/eeg/mne_sample/mne_sample-raw.fif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick aside on referencing\n",
    "EEG and ECoG both record electrical signals, that means they record the voltage of each electrode over time. Voltage always has a *reference* signal, and in the case of EEG this can be many things. For example, we can take many forms. We'll cover two common ones here.\n",
    "\n",
    "First, we'll load a few channels of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = mne.io.Raw(data_path, preload=True)\n",
    "print(raw._data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at part of the raw data\n",
    "data = raw._data[:5, :1000]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(data.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll \"reference\" everything to the first channel. By \"reference\", we simply mean that we'll store each channels value as the difference between that channel and our reference channel. e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-reference the data\n",
    "ref_chan = 0\n",
    "data_ref = data - data[ref_chan]\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(data_ref.T)\n",
    "ax.set_ylim([-.0005, .0005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, now we show each channels activity relative to the reference channel. AKA, the channels have all been referenced to a single channel.\n",
    "\n",
    "> * What kinds of benefits do you think this could give to your data analysis?\n",
    "> * What kinds of problems do you think this could introduce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we often don't reference our data to an electrode that's on the scalp. This is because there's brain activity in all of the scalp electrodes, and we don't want to mix the activity in our reference activity with whatever is going on in all the other areas of the scalp.\n",
    "\n",
    "To get around this problem, we often use a *common average reference* (CAR) for our electrodes. This basically means calculating the average activity across *all* electrodes, and then using that as a reference signal. For example, with the above data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_signal = data.mean(axis=0)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(avg_signal)\n",
    "ax.set_title('Average signal across electrodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the common average signal from each channel\n",
    "data = data - avg_signal\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(data.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the common average reference, we define each channel's activity *relative to the average activity across all electrodes*. This generally ensures that any one electrode doesn't dominate the reference, and allows you to look for differences between electrodes more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using MNE to load the referenced data\n",
    "\n",
    "In MNE, we can perform a common average reference automatically when loading in the data. set_eeg_reference() calculates the mean across all channels at each time point, and subtracts the resulting value from each channel. We'll do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = mne.io.Raw(data_path, preload=True)\n",
    "mne.set_eeg_reference(raw, copy=True)\n",
    "print(raw._data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding artifacts\n",
    "In today's lecture, we'll focus on *artifacts*, which we broadly define as components of our signal that we treat as noise. We'll try to find artifact events in our data and examine their properties.\n",
    "\n",
    "One of the simplest examples of an \"event\" is an eyeblink. This is actually a form of **noise** in the neural signal, because it doesn't reflect underlying brain activity. This is particularly a problem in EEG, because the electrical activity from your muscles will propagate across your skin and reach the sensors on your scalp.\n",
    "\n",
    "First, let's scan through the data and see if we can detect the eyeblinks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "_ = raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this person is blinking their eyes periodically. What does the \"average\" eyeblink seem to look like? Moreover, it seems like the blinks are stronger in some channels than others, why might this be?\n",
    "\n",
    "To investigate, let's plot the location of each electrode again on the scalp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = raw.plot_sensors(show_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in the previous lecture, we're picking up muscle activity from the eyes, and this activity is most clearly seen in the electrodes near the eyes.\n",
    "\n",
    "### Detecting eyeblinks automatically using MNE\n",
    "MNE has its own eyeblink detection algorithm built in. This is possible because eyeblinks always look very similar across people.\n",
    "\n",
    "It is common to refer to an eyeblink signal as an **Electrooculogram (EOG)**. This refers to the electrical activity that is generated by the muscles in your eye.\n",
    "\n",
    "Let's use the MNE eyeblinks aglorithm to do the following:\n",
    "\n",
    "* For a single channel, find moments in time where an eyeblink seems to happen. In this case, MNE will \n",
    "* Mark the timepoint for each event.\n",
    "* Define a window around each timepoint\n",
    "* Combine these windows, so our data so is now shape (n_eyeblinks, n_channels, length_window)\n",
    "\n",
    "This will return an MNE `Epochs` object, which is a way of representing data that is split up into epochs (often also called \"trials\").\n",
    "\n",
    "What seems to be a good channel for doing eyeblink detection? Why would we want one channel over another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the MNE eyeblink detection object\n",
    "epochs = mne.preprocessing.create_eog_epochs(raw, 'EEG 003')\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check out the size: (n_eyeblinks, n_channels, length_window)\n",
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNE Epochs objects are similar to Raw objects, with some extra functionality added in because of their \"epochs-based\" structure.\n",
    "\n",
    "Along with the `Epochs` object there is an array that contains information about the event times, we'll look at this below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(epochs.events.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can look at the data associated with events here:\n",
    "epochs.events[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MNE, Events arrays are structured in the shape (n_events, 3). Here's what each column means:\n",
    "\n",
    "1. The first column is the index of the event\n",
    "2. The second column is the last value of the data before that event (you can generally ignore this, or keep it at 0)\n",
    "3. The third column is the ID of the event. This is in case you have multiple event types in your data\n",
    "\n",
    "Moreover, MNE also stores information about what event types mean. There is a dictionary that maps a string name onto each event ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can see the event ID mapping here.\n",
    "# In this case, it's nothing interesting, but it'll be useful later.\n",
    "print(epochs.event_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can rename the event_id to be more meaningful\n",
    "epochs.event_id = dict(eyeblink=998)\n",
    "print(epochs.event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the data contained within this `Epochs` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The raw data for the epochs is also stored as a `_data` attribute:\n",
    "# Or you can access it using the epochs.get_data() function\n",
    "epochs._data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It is shape (n_epochs, n_channels, n_times_per_epoch)\n",
    "# In this case, n_epochs == n_eyeblinks\n",
    "epochs._data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can also access the times around each epoch\n",
    "print(epochs.times.shape)\n",
    "epochs.times[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this case, we took a 1 second window around each eyeblink.\n",
    "# If we look at our sampling frequency, we can relate this to n_timepoints\n",
    "# 1 second of time * n samples per second = total number of timepoints\n",
    "n_seconds = 1.\n",
    "n_timepoints = n_seconds * epochs.info['sfreq']\n",
    "print(n_timepoints, epochs._data.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting events\n",
    "In MNE, we can plot the data corresponding to a time window around events. This is similar to the `Raw` plotting, but it throws out all the timepoints not associated with an event. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = epochs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a little bit hard to see detail, so we'll plot fewer trials. Let's go through this plot in a little more detail:\n",
    "\n",
    "Here we see for each channel, a window of activity around each event.\n",
    "\n",
    "* We are seeing a collection of events, not a continuous timeseries like when we plotted `Raw` objects. Pay attention to the x-axis!\n",
    "* The vertical dashed black lines mark borders between events\n",
    "* Within each event we see the activity of each electrode from the `tmin` to `tmax`.\n",
    "* The solid green lines mark the event onset for each event (`t==0`).\n",
    "* The numbers at the top show the event ID for each event (in this case, they're all eyeblinks, corresponding to the event ID 998).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot at 5 events at a time. We can still scroll thorugh all the events but this view will make it easier to look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = epochs.plot(n_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * What can we say about these events? Is there a regular shape that pops out?\n",
    "> * Why does the event activity change when you compare across electrodes?\n",
    "> * Does this seem to perfectly pick out events?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging across events\n",
    "While it's important to look at the raw events, it is more useful to get a summary of what events look like in general.\n",
    "\n",
    "The simplest way to summarize activity in neuroscience is to record a number of events, then average the activity across them. We do this because of the following logic:\n",
    "\n",
    "1. Our data is comprised of two things: signal + noise\n",
    "  1. The signal is whatever the brain does in response to the world.\n",
    "  1. The noise is random fluctuations around our \"true\" signal\n",
    "1. If we record lots of instances of the same event, then we have many signals which should look the same. However, the **noise should be random, and not correlated across events**.\n",
    "1. If we average across events, then we **keep the signal, and average out the noise**.\n",
    "\n",
    "We can see this in action below. First, we'll use the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's check the size of our data to figure out across which axis to average the data\n",
    "print(epochs._data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll take the mean across all epochs, so the first axis\n",
    "mean_epoch = epochs._data.mean(axis=0)\n",
    "print(mean_epoch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll plot the average eyeblink for *each channel*\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochs.times, mean_epoch.T)\n",
    "ax.set_title('Mean eyeblink for **each channel**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now the average across all channels\n",
    "print(mean_epoch.shape)\n",
    "mean_epoch = mean_epoch.mean(axis=0)\n",
    "print(mean_epoch.shape)\n",
    "\n",
    "# Now we'll plot the result\n",
    "mean_epoch = ds.Table().with_columns([('data', mean_epoch),\n",
    "                                      ('time', epochs.times)])\n",
    "mean_epoch.plot('time', 'data')\n",
    "plt.title('Mean eyeblink for **all channels**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's what an eyeblink looks like. We can also quickly glance at what the eyeblink looks like by using MNE's averaging and plotting functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Average across trials, and then plot the result for each channel.\n",
    "average = epochs.average()\n",
    "_ = average.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalp Topographic Maps\n",
    "As we've noted several times, the pattern of activity changes across both time *and* channels. For example, eyeblinks become less strong as we move away from the eyes. We can visualize a pattern of activity as you move across electrodes with a *scalp topography*. This is a way showing the activity at a moment in time, where each electrode's color reflects its voltage.\n",
    "\n",
    "In MNE there are quick functions for plotting scalp topographies with EEG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = average.plot_topomap(times=[-.5, 0, .5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even combine the above plot with our time-varying plots, to see how the scalp topography changes over the course of the trial. Below we'll plot the average activity for each electrode, and the scalp topography at a few moments of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = average.plot_joint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * You might notice that the color seems a little bit off here, why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot each waveform as an individual plot at the electrode's location. This is called a topo-plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can also amek a \"topographic\" plot, or \"topoplot\"\n",
    "# In this case, each plot is the location of a sensor.\n",
    "_ = average.plot_topo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Where do you think the front of the brain is on the plot above? Why?\n",
    "> * What are some reasons you can think of for using a topographic map? What about a topographic plot?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

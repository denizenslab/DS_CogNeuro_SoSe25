{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression, Correlation, and Modeling\n",
    "In this lab, we'll explore how regression and correlation look in higher frequency ranges compared with raw signals.\n",
    "\n",
    "The value in extracting different neural features is that they often have more favorable properties. For example, perhaps we can find a neural signal that is more spatially-localized, or has a better signal-to-noise ratio. Much of research in cognitive neuroscience aims at finding such signals.\n",
    "\n",
    "We'll finish by using regression to relate patterns of activity to different kinds of stimuli. Regression is a powerful tool for using external events or stimulus values to predict patterns of brain activity, something we'll focus on in the second half of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datascience as ds\n",
    "import neurods as nds\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data and task\n",
    "For this lab you'll be using the same ECoG dataset that we've used before. However, we'll look at a different component of the ECoG signal (high-frequency activity). We'll look at this signal's relationship to GFP. Finally, we'll use regression to tease apart which channels are responding to one trial type over another. This will tell us which channels respond most strongly to \"consonant\" vs. \"dissonant\" sounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll load the same ECoG dataset we've used before, along with sensor positions and a picture of the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_ecog = '../../data/ecog/chords_task/'\n",
    "raw = mne.io.Raw(path_ecog + 'ecog_resamp-raw.fif', preload=True)\n",
    "time = ds.Table.read_table(path_ecog + 'meta_time.csv', index_col=0)\n",
    "meta_elecs = ds.Table.read_table(path_ecog + 'meta_chans.csv')\n",
    "meta_elecs = meta_elecs.where('use', 1)\n",
    "im = plt.imread(path_ecog + 'brain.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Drop any channels marked as \"bad\" in `meta_elecs` so that we don't bias results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One metric for signal-to-noise is the extent to which each electrode is correlated with all the other electrodes. If there are large amounts of correlation, it means that you have less information present in the data. \n",
    "\n",
    "> Think of it this way - if I have 3 signals and they're correlated, then knowing something about the first signal tells me a lot about the other two. This means that any information present in the first signal (e.g., did I just play sound A or sound B) will likely also be present in the other two. This means that the *total* amount of information in the 3 signals is relatively lower than if they were not correlated. If they are *not* correlated, then each signal is independent of the other, and they can store potentially different kinds of information.\n",
    "\n",
    "* Calculate the correlation matrix for all channels in the raw data\n",
    "* Plot it using `imshow`. What pattern do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there's a similar spatial pattern of correlation as we saw with EEG signals. However, as we have seen last week one of the benefits of using ECoG is that it contains activity in *higher frequencies*. Let's take a look at these higher frequencies in the context of spatial correlations.\n",
    "\n",
    "* Extract the amplitude for a range of frequencies (using `extract_amplitude()`)\n",
    "  * Use 5 frequencies linearly spaced from 70 to 150 Hz (and then averaged together)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "def extract_amplitude(inst, freqs, n_cycles=7, normalize=False):\n",
    "    \"\"\"Extract the time-varying amplitude for a frequency band.\n",
    "\n",
    "    If multiple freqs are given, the amplitude is calculated at each frequency\n",
    "    and then averaged across frequencies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inst : instance of Raw or Epochs\n",
    "        The data to have amplitude extracted.\n",
    "    freqs : array of ints/floats, shape (n_freqs)\n",
    "        The frequencies to use. If multiple frequencies are given, amplitude\n",
    "        will be extracted at each and then averaged between frequencies.\n",
    "    n_cycles : int\n",
    "        The number of cycles to include in the filter length for the wavelet.\n",
    "    normalize : bool\n",
    "        Normalize the power of each band by its mean before combining.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    inst : mne instance, same type as input 'inst'\n",
    "        The MNE instance with channels replaced with their time-varying\n",
    "        amplitude for the supplied frequency range.\n",
    "    \"\"\"\n",
    "\n",
    "    # Data checks\n",
    "    freqs = np.atleast_1d(freqs)\n",
    "    if not inst.preload:\n",
    "        raise ValueError('Data must be preloaded.')\n",
    "\n",
    "    data = inst.get_data()\n",
    "    data=data[np.newaxis, :]\n",
    "    sfreq = inst.info['sfreq']\n",
    "    n_channels, n_times = data.shape[1], data.shape[2]\n",
    "\n",
    "    # Initialize array to store the band amplitudes\n",
    "    bands = np.zeros((1, n_channels, n_times))\n",
    "\n",
    "    for ifreq in tqdm(freqs, desc=\"Processing frequencies\"):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            # Perform time-frequency decomposition\n",
    "            tfr_complex = mne.time_frequency.tfr_array_morlet(\n",
    "                data, sfreq=sfreq, freqs=[ifreq], n_cycles=n_cycles, output='complex'\n",
    "            )\n",
    "        \n",
    "        # Compute the amplitude (absolute value of the complex TFR)\n",
    "        band = np.abs(tfr_complex[:, :, 0, :])\n",
    "        \n",
    "        if normalize:\n",
    "            band /= band.mean(axis=-1, keepdims=True)\n",
    "\n",
    "        bands += band\n",
    "\n",
    "    # Average across frequencies\n",
    "    bands /= len(freqs)\n",
    "\n",
    "    # Create a new MNE object with the amplitude data\n",
    "    inst_amplitude = inst.copy()\n",
    "    inst_amplitude._data = bands.reshape(n_channels,n_times)\n",
    "\n",
    "    return inst_amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the this dataset with the `.plot` method.\n",
    "* Note whether there seem to be large correlations between channels. How does this related to the raw (non high-frequency) data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What do you notice about the signal above? When one channel increases, do the others also increase?\n",
    "* How is it different from raw data?\n",
    "* Does it seem noisier or cleaner?\n",
    "\n",
    "Next, we'll take a look at the correlation matrix for this high-frequency signal.\n",
    "\n",
    "* Calculate the correlation matrix for the `Raw` data you've extracted.\n",
    "* use `imshow` to plot the results. Use the same color limits that you plotted above (with the `vmin` and `vmax` parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How does this compare with the correlation matrix for the raw data?\n",
    "* What does this say about these high-frequency signals?\n",
    "* What does this mean for our ability to use these signals to answer questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event-related activity and regression\n",
    "Next, we'll take a look at the event-related activity for this data.\n",
    "\n",
    "* Using the \"meta time\" information, create an MNE events array. Only use the \"consonants\" events.\n",
    "* Then, turn the `Raw` data into an `Epochs` object with these events\n",
    "* Finally, plot the average event-related response once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What difference do you see in this plot compared with the raw epochs?\n",
    "* Is it cleaner or noisier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll investigate how the high-frequency activity is distributed across ECoG channels by calculating the global field power using these signals.\n",
    "\n",
    "* Calculate the GFP of the high-frequency amplitude that you calculated above\n",
    "* Plot the average GFP over time.\n",
    "* How does this signal compare to the one calculated from raw data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, fit a regression model that predicts the GFP from the high-frequency amplitude of each electrode.\n",
    "  * Don't forget to scale the electrode data before fitting!\n",
    "  * Use the `LinearRegression` estimator in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, plot the coefficients as a line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How does this plot compare with the plot using raw data?\n",
    "  * Why do you think this is?\n",
    "\n",
    "* Is the scale of these coefficients different from the ones above?\n",
    "  * Why do you think this is?\n",
    "\n",
    "\n",
    "* Finally, plot the coefficients on the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare this with the model coefficients we plotted in lecture\n",
    "  * How overlapping are these two plots?\n",
    "  * Why would there be differences between them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with external stimuli\n",
    "Finally, we'll relate these neural signals to activity in the world. When we use a pattern of stimulus activity as inputs to a regression model that predicts brain activity as an output, it's called an *encoding model*. We'll see if the type of sound played results in different types of brain activity.\n",
    "\n",
    "If you'll recall, this subject listened to \"consonant\" and \"dissonant\" chords. There was also occasionally the sound of a cat meowing. That gives us 3 types of auditory stimuli. Let's see if we can use these values to predict different amounts of neural activation.\n",
    "\n",
    "* First, convert the event timings into an MNE \"events\" array. Make sure you include times for consonants, dissonants, and meows.\n",
    "* Create a dictionary that maps event type names onto integers\n",
    "* Then construct an MNE Epochs object from the high-frequency amplitude we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmin, tmax = -.5, .5\n",
    "\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the average activity for each event type (you should create 3 different plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the regression, we'll just use a single summary statistic of each trial instead of the fully time-varying neural signals.\n",
    "\n",
    "* Calculate the mean amplitude of the ecog data from 0 seconds to 3 seconds. Do this for each trial. The output should be shape (n_trials, n_channels)\n",
    "  * This will be the output of the regression model.\n",
    "  * Call the variable \"y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know if stimulus type predicts evoked high-frequency activity. To use this in regression, we'll use *binary variables* to code for each type of stimulus. This is a matrix with 3 columns, one column per stimulus type. For each row, a `1` in a column means that the feature for that column was played. Each row will be a trial, so we can use this to code the stimulus type for every trial.\n",
    "\n",
    "* Construct a numpy array of zeros of shape (n_trials, 3). We choose 3 because there are 3 stimulus types. Call it `X`.\n",
    "* Iterate through each trial, and determine the stimulus that was played for that trial. Insert a `1` into the row/column of `X` according to that stimulus type.\n",
    "  * The final result will be an array of shape `(n_trials, 3)`, where each row has two 0s and a single 1, encoding which stimulus type was played for that trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the makings for a regression model. We have a collection of inputs (X) and a collection of outputs (y), we have several instances of each.\n",
    "\n",
    "* Use the `LinearRegression` sklearn estimator to fit a model that predicts y from X.\n",
    "  * Do *not* scale X this time. It is a binary variable of 0s and 1s, so scaling it doesn't make any sense and will mess up the regression.\n",
    "\n",
    "> Note - you can fit multiple output variables at once by passing `y` as a matrix instead of a 1-D vector. `y` is expected to be shape `(n_samples, n_outputs)` (sklearn calls them `n_targets` instead of `n_outputs`). So in our case, we are fitting `n_channels` number of models. We'll get a set of coefficients for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model creates a set of coefficients for each output you've included in `y`. It describes how the three stimulus types relate to the activity of `y`. Lower values mean that the presence of that stimulus type will result in less activity for that channel. Higher values mean the presence of that stimulus type increases the activity for that channel.\n",
    "\n",
    "* Visualize the coefficients for all of our models simultaneously with `imshow`. The model coefficients will be stored as an attribute `.coef_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What do you notice about the coefficients above? Do you see any patterns?\n",
    "* Does one stimulus type seem to result in more activity than others? If so, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the \"preferred\" stimulus for each electrode on the brain.\n",
    "\n",
    "* For each electrode, find the stimulus type with the biggest coefficient. Code this as a vector of length `n_channels` with integers representing the stimulus type. Look into the `argmax` function to do this quickly.\n",
    "* Plot the results on the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In regions of auditory cortex (on the temporal lobe) what type of stimulus is generally preferred?\n",
    "* What about in other regions of the brain? Is the same stimulus preferred everywhere? What about towards the front of the brain?\n",
    "\n",
    "This is a very simple version of a neural *tuning map*. It tells is which regions of the brain are most responsive to certain kinds of features. We'll explore their use in subsequent classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at an interactive version\n",
    "Below we've written some code that creates a fancier interactive plot in python. If you've got your analysis code working above, it should create a plot that shows you amplitude values for each electrode and each condition.\n",
    "\n",
    "You can relate the coefficients (to the right) to the amplitude values (to the left). The slider lets you move through electrodes, so you can see how the coefficients reflect differences in the electrode activity for each condition.\n",
    "\n",
    "**Note: ** The following pieces of data need to have specific names for this to work, they are below:\n",
    "* Your `LinearRegression` model must be assigned to a variable called \"`mod`\"\n",
    "* The input data must be assigned to a variable `X`\n",
    "* The output data must be assigned to a variable `y`\n",
    "* The MNE epochs data must be called `epochs`.\n",
    "\n",
    "If you can't get this working then don't worry, it's just for demonstration. I'll show a live version in class if people have trouble with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_effect(ix_elec=0):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    for ii, ax in enumerate(axs[:3]):\n",
    "        ax.scatter(X[:, ii], y[:, ix_elec])\n",
    "        ax.set_title('Condition\\n{}'.format(\n",
    "                {val: key for key, val in epochs.event_id.items()}[ii + 1]))\n",
    "        ax.set_xticks([0, 1])\n",
    "    \n",
    "    axs[3].imshow(mod.coef_, aspect='auto', interpolation='nearest',\n",
    "               vmin=-2, vmax=2, cmap='coolwarm')\n",
    "    axs[3].text(3, ix_elec + 3, '<--', color='k', fontsize=40)\n",
    "    fig.suptitle('Effect for channel\\n{}'.format(epochs.ch_names[ix_elec]),\n",
    "                 y=1.1, fontsize=20)\n",
    "    axs[3].set_title('Coefficients per condition')\n",
    "    axs[3].set_xticks([0, 1, 2])\n",
    "    axs[3].set_xticklabels(epochs.event_id.keys())\n",
    "    axs[0].set_ylabel('High-Frequency Activity')\n",
    "    _ = plt.setp(axs[:3], ylim=[-5, 15])\n",
    "    axs[0].set_xlabel('Stimulus type present (1) vs. not present (0)')\n",
    "\n",
    "_ = interact(plot_effect,\n",
    "             ix_elec=widgets.IntSlider(min=0, max=y.shape[-1],\n",
    "                               step=1, continuous_update=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
